input {
	#stdin {}
	file{
		path => "/home/hashir/Documents/LogstashFiles/testxml.xml"
		start_position => "beginning"
		sincedb_path => "/dev/null"
		type => "xml"
		codec => multiline {
			pattern => "^<\?xml .*\?>"
			negate => "true"
			what => previous
			auto_flush_interval => 1
		}
	}
}
filter{
	xml {
		source => "message"
		target => "doc"
	}
	split {
		field => "doc[prefix]"
	}
	split {
		field => "doc[book]"
	}
	split {
		field => "doc[book][otherInfo]"
	}
	mutate {
		add_field => {"prefix" => "%{doc[prefix]}" }
		add_field => {"bkId" => "%{doc[book][id]}" }
		add_field => {"bkName" => "%{doc[book][name]}" }
		add_field => {"author" => "%{doc[book][otherInfo][author]}" }
		add_field => {"pages" => "%{doc[book][otherInfo][page]}" }
	}
	ruby {
		code => "event.set('Shelf', (event.get('bkId').to_i % 2 == 1 ? 1 : 2));
			convertedId = event.get('bkId').rjust(10,'0');
			event.set('bkId', event.get('prefix')+'-'+convertedId);"
	}
	#jdbc_streaming {
		#jdbc_driver_library => "/usr/share/java/mysql-connector-java-5.1.38.jar"
		#jdbc_driver_class => "com.mysql.jdbc.Driver"
		#jdbc_connection_string => "jdbc:mysql://localhost:3306/testdb"
		#jdbc_user => "root"
		#jdbc_password => "tiroot"
		#statement => "select now() as now"
		#target => "logs"
	#}
	ruby {
		code => "
			#logsArr = event.get('logs');
			#event.set('Log',logsArr[0].to_s);
			event.set('Created_Date',event.get('@timestamp').to_s[0,10]);"
	}
	mutate{
		remove_field => ["@version","host","@timestamp","message","doc","type","tags","path","prefix","logs"]
	}
}
output{
	stdout{
		codec => rubydebug
	}
	#elasticsearch{
		#hosts => "http://localhost:9200"
		#index => "esindex"
	#}
}
